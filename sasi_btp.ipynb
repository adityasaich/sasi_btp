{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sasi_btp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsIhNTWpqvcDXEwNBtAwNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityasaich/sasi_btp/blob/main/sasi_btp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU10kfw836GQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnZSvGkM4KLP"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cay1gNP4qgZ"
      },
      "source": [
        "id = '18xGNPuvbXGSN97g0CzI1tIBl81zJrToF'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbxReImg4oXL"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('dataset.csv')  \n",
        "df_input = pd.read_csv('dataset.csv')\n",
        "#df_input = df_input.sample(n=50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR50-2tVF7hc"
      },
      "source": [
        "#url = 'https://raw.githubusercontent.com/adityasaich/sasi_btp/main/dataworld_set.csv?token=ALPKPQCX3COGEIP65QDO2V3BR5QT6'\n",
        "#df_input = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoVLRIQIRUk7"
      },
      "source": [
        "def deviationTransform(arr):\n",
        "  m = np.mean(arr)\n",
        "  d = np.std(arr)\n",
        "  return [m,d]\n",
        "def minMaxTransform(arr):\n",
        "  min = np.min(arr)\n",
        "  max = np.max(arr)\n",
        "  return [min,max-min]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eosEdO5wVqD"
      },
      "source": [
        "#pre-processing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "df_input = df_input[df_input['Area'] > 0 ]\n",
        "df_input = df_input[df_input['Production'] > 0 ]\n",
        "df_input[\"ProductionPerArea\"] = ((df_input[\"Production\"])/(df_input[\"Area\"]))\n",
        "#dropping columns which are not used\n",
        "df_input = df_input.drop(columns=['District_Name','Area','Production'])\n",
        "#replace empty strings with nan\n",
        "df_input = df_input.replace(r'^\\s*$', np.NaN, regex=True)\n",
        "#drop null values\n",
        "df_input = df_input.dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlfcyeRW4m4a"
      },
      "source": [
        "x = df_input['ProductionPerArea']\n",
        "print(x.describe())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot((x), vert=False, showmeans=True, meanline=True,\n",
        "           labels=('x'), patch_artist=True,\n",
        "           medianprops={'linewidth': 2, 'color': 'purple'},\n",
        "           meanprops={'linewidth': 2, 'color': 'red'})\n",
        "plt.show()\n",
        "hist, bin_edges = np.histogram(x, bins=20)\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(x, bin_edges, cumulative=False)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCHx2bow4jXP"
      },
      "source": [
        "categorical_columns = ['State_Name', 'Crop' ,'Season']\n",
        "#label encoder dict\n",
        "labels_dict = {}\n",
        "#scaling dict\n",
        "scaling_dict = {}\n",
        "for column in categorical_columns:\n",
        "  le = LabelEncoder()\n",
        "  le.fit(df_input[column])\n",
        "  df_input[column] = le.transform(df_input[column])\n",
        "  labels_dict[column] = list(le.classes_)\n",
        "  scaling_params = minMaxTransform(np.array(df_input[column]))\n",
        "  df_input[column] = (df_input[column] - scaling_params[0])/scaling_params[1]\n",
        "  scaling_dict[column] = scaling_params\n",
        "scaling_params = deviationTransform(np.array(df_input['ProductionPerArea']))\n",
        "df_input['ProductionPerArea'] = (df_input['ProductionPerArea'] - scaling_params[0])/scaling_params[1]\n",
        "scaling_dict['ProductionPerArea'] = scaling_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhLSV05ibYEp"
      },
      "source": [
        "labels_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPW9kPllZttA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_small = df_input\n",
        "df_small.columns.name = None\n",
        "df=df_small\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLIV-y_raTsL"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def classify(clf,x_train,x_test,y_train,y_test):\n",
        "  clf.fit(x_train,y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  print(y_pred)\n",
        "  y_train_pred = clf.predict(x_train)\n",
        "  print(mean_squared_error(y_train, y_train_pred))\n",
        "  print(mean_squared_error(y_test, y_pred))\n",
        "  y_pred = np.array(y_pred)\n",
        "  y_test = np.array(y_test)\n",
        "  for i in range(y_test.size):\n",
        "    if(y_test[i]>15):\n",
        "      print(i,y_test[i],y_pred[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUFesFqCbCFo"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regresser = RandomForestRegressor(n_estimators = 10 ,random_state = 0)\n",
        "print(\"\\t\\t\\t random-forest classifier\")\n",
        "classify(regresser,x_train,x_test,y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYxMkyz-P8Rg"
      },
      "source": [
        "regresser.get_params(\"true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ5PqbKvufyO"
      },
      "source": [
        "#linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "print(\"\\t\\t\\t linear-regression classifier\")\n",
        "classify(reg,x_train,x_test,y_train,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA5ikFezrC8K"
      },
      "source": [
        "json_params = {}\n",
        "json_params['labels'] = labels_dict\n",
        "json_params['scaling'] = scaling_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7nIyMmNMaWI"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}